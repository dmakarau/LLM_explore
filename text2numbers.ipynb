{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOqiVlPfRnoAUBzlfsw8S9k"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Create and visualize tokens**"
      ],
      "metadata": {
        "id": "wRud_Fkwg9GP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "MdxDgBGZPFo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list of sentences\n",
        "text = [ 'All that we are is the result of what we have thought',\n",
        "         'To be or not to be that is the question',\n",
        "         'Be yourself everyone else is already taken' ]"
      ],
      "metadata": {
        "id": "m845ir4cg_PB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a vocab of unique words\n",
        "allwords = []\n",
        "for phrase in text:\n",
        "  words = re.split(r'\\s', phrase.lower())\n",
        "  allwords.extend(words)\n",
        "vocab = sorted(set(allwords))\n",
        "vocab"
      ],
      "metadata": {
        "id": "xKWhEnYqhQRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create an enconder and decoder disctionaries\n",
        "word2idx = {}\n",
        "for i, word in enumerate(vocab):\n",
        "  word2idx[word] = i\n",
        "idx2word = {}\n",
        "for i, word in enumerate(vocab):\n",
        "  idx2word[i] = word\n",
        "\n",
        "word2idx"
      ],
      "metadata": {
        "id": "_PMATTIShXQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the encode function that takes text input and gives a list of integers as tokens\n",
        "def encode(phrase):\n",
        "  words = re.split(r'\\s', phrase.lower())\n",
        "  return [ word2idx[word] for word in words ]\n"
      ],
      "metadata": {
        "id": "JLoGkUZLSRWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = encode('we already are the result of what everyone else already thought')\n",
        "print(tokens)"
      ],
      "metadata": {
        "id": "0a4Ell2sZv9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the decode function that takes list of tokens as integers and gives the text\n",
        "def decode(tokens_list):\n",
        "  return ' '.join(idx2word[i] for i in tokens_list)\n"
      ],
      "metadata": {
        "id": "x05E9ytZWz5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "phrase = decode(tokens)\n",
        "print(phrase)"
      ],
      "metadata": {
        "id": "5ifdr8TNZ1jI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab) # Just a reminder what words in the vocabulary do we have"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnaLaQ6OaCBW",
        "outputId": "20475d0a-8309-463f-dc97-2b22e64dee11"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['all', 'already', 'are', 'be', 'else', 'everyone', 'have', 'is', 'not', 'of', 'or', 'question', 'result', 'taken', 'that', 'the', 'thought', 'to', 'we', 'what', 'yourself']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a phrase, using vocab\n",
        "another_phrase = 'we have thought what is the question'\n",
        "# encode text to tokens\n",
        "tokens = encode(another_phrase)\n",
        "print(tokens)\n",
        "\n",
        "# decode tokens to text\n",
        "phrase_decoded = decode(tokens)\n",
        "print(phrase_decoded)"
      ],
      "metadata": {
        "id": "Vf-6RZPPaD2n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}