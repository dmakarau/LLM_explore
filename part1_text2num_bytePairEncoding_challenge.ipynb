{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXzDDQQW3PRI8I0NIVRC7c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dmakarau/LLM_explore/blob/main/part1_text2num_bytePairEncoding_challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize the vocabulary"
      ],
      "metadata": {
        "id": "7ahGNpXEiaT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "Xfo-wdXiidFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# some text with lots of repetitions\n",
        "text = 'like liker love lovely hug hugs hugging hearts'\n",
        "\n",
        "chars = list(set(text))\n",
        "chars.sort()\n",
        "print(chars)\n",
        "\n",
        "for l in chars:\n",
        "  print(f'{l} appears {text.count(l)} times')"
      ],
      "metadata": {
        "id": "X4M4B3NqihFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make a vocabulary\n",
        "vocab = { word: i for i, word in enumerate(chars)}\n",
        "vocab"
      ],
      "metadata": {
        "id": "_SvZMds1ixwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert text to a list\n",
        "origtext = list(text)\n",
        "print(text)\n",
        "print(origtext)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKDaOafni6PT",
        "outputId": "732f6857-b799-4d11-903a-03db12df76f6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "like liker love lovely hug hugs hugging hearts\n",
            "['l', 'i', 'k', 'e', ' ', 'l', 'i', 'k', 'e', 'r', ' ', 'l', 'o', 'v', 'e', ' ', 'l', 'o', 'v', 'e', 'l', 'y', ' ', 'h', 'u', 'g', ' ', 'h', 'u', 'g', 's', ' ', 'h', 'u', 'g', 'g', 'i', 'n', 'g', ' ', 'h', 'e', 'a', 'r', 't', 's']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now using functions"
      ],
      "metadata": {
        "id": "gbQyGMPyjYS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# >---------------------------------------------\n",
        "def get_pair_stats(text2pair):\n",
        "  token_pairs = dict()\n",
        "\n",
        "  #loop over the tokens\n",
        "  for i in range(len(text2pair) - 1):\n",
        "    # create a pari\n",
        "    pair = text2pair[i] + text2pair[i + 1]\n",
        "\n",
        "    # increase pair sequences\n",
        "    if pair in token_pairs:\n",
        "      token_pairs[pair] += 1\n",
        "    else:\n",
        "      token_pairs[pair] = 1\n",
        "  return token_pairs\n",
        "# >---------------------------------------------\n",
        "\n",
        "# >---------------------------------------------\n",
        "def update_vocab(token_pairs, vocab):\n",
        "\n",
        "  # find the most frequent pair\n",
        "  idx = np.argmax(list(token_pairs.values())) # corrected line\n",
        "  newtok = list(token_pairs.keys())[idx]\n",
        "\n",
        "  # update the vocab\n",
        "  vocab[newtok] = max(vocab.values()) + 1\n",
        "  return vocab, newtok\n",
        "# >---------------------------------------------\n",
        "\n",
        "# >---------------------------------------------\n",
        "def generate_new_token_sequence(prevtext, newtoken):\n",
        "  # initialize a new text list\n",
        "  newtext = []\n",
        "\n",
        "  # loop through the list\n",
        "  i = 0\n",
        "  while (i < len(prevtext) - 1):\n",
        "    if (prevtext[i] + prevtext[i + 1]) == newtoken:\n",
        "      newtext.append(newtoken)\n",
        "      i += 2\n",
        "    #not a pair\n",
        "    else:\n",
        "      newtext.append(prevtext[i])\n",
        "      i += 1\n",
        "  # Add the last character if the loop finished on the second to last character\n",
        "  if i == len(prevtext) - 1:\n",
        "      newtext.append(prevtext[i])\n",
        "  return newtext\n",
        "# >---------------------------------------------"
      ],
      "metadata": {
        "id": "4gRicQ2LjZWq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 1"
      ],
      "metadata": {
        "id": "5gjdQvUSjopD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# re-init the vocab\n",
        "vocab = { word: i for i, word in enumerate(chars)}\n",
        "print(f'Vocab has {len(vocab)} tokens.')\n",
        "\n",
        "wished_vocab_size = 25\n",
        "\n",
        "# make a copy of the original text\n",
        "edited_text = origtext.copy()\n",
        "\n",
        "while len(vocab) < wished_vocab_size:\n",
        "  # find and count pairs\n",
        "  pairs = get_pair_stats(edited_text)\n",
        "\n",
        "  # update the dictionary\n",
        "  vocab,newtoken = update_vocab(pairs, vocab)\n",
        "\n",
        "  # get a list of new tokens\n",
        "  edited_text = generate_new_token_sequence(edited_text, newtoken)\n",
        "  print(f'Vocab has {len(vocab)} tokens.')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "230j9WbqjqL_",
        "outputId": "a558a23b-ecd9-48c6-bb8b-015727fd711f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab has 16 tokens.\n",
            "Vocab has 17 tokens.\n",
            "Vocab has 18 tokens.\n",
            "Vocab has 19 tokens.\n",
            "Vocab has 20 tokens.\n",
            "Vocab has 21 tokens.\n",
            "Vocab has 22 tokens.\n",
            "Vocab has 23 tokens.\n",
            "Vocab has 24 tokens.\n",
            "Vocab has 25 tokens.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# final tokenized text\n",
        "print(edited_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPZ0Muvzkstg",
        "outputId": "0c079917-1582-4458-e24d-cc7f301fb99e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['l', 'ike', ' l', 'ike', 'r', ' love', ' love', 'l', 'y', ' hug', ' hug', 's', ' hug', 'g', 'i', 'n', 'g', ' h', 'e', 'a', 'r', 't', 's']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the final vocab\n",
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2n-jxC18k01h",
        "outputId": "71e35d66-26d5-4cb7-bc15-5ac39a32dee0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ': 0,\n",
              " 'a': 1,\n",
              " 'e': 2,\n",
              " 'g': 3,\n",
              " 'h': 4,\n",
              " 'i': 5,\n",
              " 'k': 6,\n",
              " 'l': 7,\n",
              " 'n': 8,\n",
              " 'o': 9,\n",
              " 'r': 10,\n",
              " 's': 11,\n",
              " 't': 12,\n",
              " 'u': 13,\n",
              " 'v': 14,\n",
              " 'y': 15,\n",
              " ' h': 16,\n",
              " ' l': 17,\n",
              " ' hu': 18,\n",
              " ' hug': 19,\n",
              " 'ik': 20,\n",
              " 'ike': 21,\n",
              " ' lo': 22,\n",
              " ' lov': 23,\n",
              " ' love': 24}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}